{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdLBswKQa2PTnKNrN2WK6Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishankgp890/langchain-tutorials/blob/main/Chat_completion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S-EIui2ujhM",
        "outputId": "7bb11b70-9085-40f5-8f19-d652476372ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.4 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYRGif28tWaU",
        "outputId": "1f784f07-bf27-449b-efb4-2785f56333ea"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"content\": \"1. The University of Home Services used to use a device called SSD for job-related data entry until 2016.\\n2. The technicians now use a take-out app for their work.\\n3. The app shows the technician's weekly statistics, job list, and clocking mechanism.\\n4. Technicians do not get to choose which job they start with, but can mix and match subsequent jobs.\\n5. The job details in the app include information such as whether cash needs to be collected.\\n6. The app helps with analytics and categorizing service orders.\",\n",
            "        \"role\": \"assistant\"\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1680740668,\n",
            "  \"id\": \"chatcmpl-727iOMWQzzzGqGWLbqZPRTq59upAr\",\n",
            "  \"model\": \"gpt-3.5-turbo-0301\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 112,\n",
            "    \"prompt_tokens\": 927,\n",
            "    \"total_tokens\": 1039\n",
            "  }\n",
            "}\n",
            "1. The University of Home Services used to use a device called SSD for job-related data entry until 2016.\n",
            "2. The technicians now use a take-out app for their work.\n",
            "3. The app shows the technician's weekly statistics, job list, and clocking mechanism.\n",
            "4. Technicians do not get to choose which job they start with, but can mix and match subsequent jobs.\n",
            "5. The job details in the app include information such as whether cash needs to be collected.\n",
            "6. The app helps with analytics and categorizing service orders.\n",
            "\n",
            "\n",
            "\n",
            " 1 of 9  -  1. The University of Home Services used to use a device called SSD for job-related data entry until 2016. 2. The technicians now use a take-out app for their work. 3. The app shows the technician's weekly statistics, job list, and clocking mechanism. 4. Technicians do not get to choose which job they start with, but can mix and match subsequent jobs. 5. The job details in the app include information such as whether cash needs to be collected. 6. The app helps with analytics and categorizing service orders.\n",
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"content\": \"1. Technicians are not just repair persons, but also salespersons who try to upsell clean and maintenance offers and home warranty offers.\\n2. The customer details include name, address, and phone number, and allow the technician to call ahead if necessary.\\n3. Helpers are assigned for heavy lifting work, such as HVAC repair or repairing large refrigerators.\\n4. Helpers are rarely assigned in the first visit, but rather in subsequent visits if needed.\\n5. Parts can be a bigger issue and can lead to spending more time on a repair.\\n6. Technicians can mark a reschedule in the take-up app if a helper is needed on a subsequent visit.\\n7. The contracts offered by technicians are not customized to individual customers.\",\n",
            "        \"role\": \"assistant\"\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1680740690,\n",
            "  \"id\": \"chatcmpl-727ikZkiPzhcuNgyagHB8cTKIcbBZ\",\n",
            "  \"model\": \"gpt-3.5-turbo-0301\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 148,\n",
            "    \"prompt_tokens\": 877,\n",
            "    \"total_tokens\": 1025\n",
            "  }\n",
            "}\n",
            "1. Technicians are not just repair persons, but also salespersons who try to upsell clean and maintenance offers and home warranty offers.\n",
            "2. The customer details include name, address, and phone number, and allow the technician to call ahead if necessary.\n",
            "3. Helpers are assigned for heavy lifting work, such as HVAC repair or repairing large refrigerators.\n",
            "4. Helpers are rarely assigned in the first visit, but rather in subsequent visits if needed.\n",
            "5. Parts can be a bigger issue and can lead to spending more time on a repair.\n",
            "6. Technicians can mark a reschedule in the take-up app if a helper is needed on a subsequent visit.\n",
            "7. The contracts offered by technicians are not customized to individual customers.\n"
          ]
        }
      ],
      "source": [
        "# Text omletion is slower and costlier than chat completion . \n",
        "\n",
        "import openai\n",
        "import os\n",
        "from time import time,sleep\n",
        "import textwrap\n",
        "import re\n",
        "\n",
        "\n",
        "def open_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
        "        return infile.read()\n",
        "\n",
        "\n",
        "openai.api_key = open_file('openaiapikey.txt')\n",
        "\n",
        "\n",
        "def save_file(content, filepath):\n",
        "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
        "        outfile.write(content)\n",
        "\n",
        "\n",
        "def gpt3_completion(prompt, model='gpt-3.5-turbo', temp=0.2,tokens=3000, freq_pen=0.25, pres_pen=0.0, stop=['<<END>>']):\n",
        "    max_retry = 1\n",
        "    retry = 0\n",
        "    n=0\n",
        "    while True:\n",
        "        try:\n",
        "            completion = openai.ChatCompletion.create(\n",
        "                model=model,\n",
        "                temperature=temp,\n",
        "                max_tokens=tokens,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                #top_p=top_p,\n",
        "                #frequency_penalty=freq_pen,\n",
        "                #presence_penalty=pres_pen,\n",
        "                stop=stop)\n",
        "            #print(completion)\n",
        "            print(completion)\n",
        "            input(\"Press any key to continue...\")\n",
        "            text = completion['choices'][0]['message']['content']\n",
        "            print(text)\n",
        "            input(\"\\nPress any key to continue...\")\n",
        "            text = re.sub('\\s+', ' ', text)\n",
        "            filename = '%s_gpt3.txt' % time()\n",
        "            with open('gpt3_logs/%s' % filename, 'w') as outfile:\n",
        "                outfile.write('PROMPT:\\n\\n' + prompt + '\\n\\n==========\\n\\nRESPONSE:\\n\\n' + text)\n",
        "            return text\n",
        "        except Exception as oops:\n",
        "            retry += 1\n",
        "            if retry >= max_retry:\n",
        "                return \"GPT3 error: %s\" % oops\n",
        "            print('Error communicating with OpenAI:', oops)\n",
        "            sleep(1)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    alltext = open_file('ks1_transcript.txt')\n",
        "    chunks = textwrap.wrap(alltext, 4000)\n",
        "    result = list()\n",
        "    count = 0\n",
        "    for chunk in chunks:\n",
        "        count = count + 1\n",
        "        prompt = open_file('prompt_final.txt').replace('<<SUMMARY>>', chunk)\n",
        "        prompt = prompt.encode(encoding='ASCII',errors='ignore').decode()\n",
        "        #print(prompt)\n",
        "        summary = gpt3_completion(prompt)\n",
        "        print('\\n\\n\\n', count, 'of', len(chunks), ' - ', summary)\n",
        "        result.append(summary)\n",
        "    save_file('\\n\\n'.join(result), 'output_%s.txt' % time())"
      ]
    }
  ]
}